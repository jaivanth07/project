<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transfer Learning with PyTorch</title>
    <link rel="stylesheet" type="text/css" href="style.css">
    <link rel="stylesheet" type="text/css" href="build.css">
    <!-- Include Prism.js and your selected plugins -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.25.0/themes/prism-okaidia.css">
    <link rel="stylesheet" type="text/css" href="rspt.css">

    <!-- Your custom CSS styles -->
    <link rel="stylesheet" type="text/css" href="styles.css">
</head>
<body>
    <!-- Header Section -->
    <nav class="navbar">
        <div class="container">
            <a href="index.html"> <img src="logo.png" alt="Logo" class="logo"></a>
            <ul class="nav-links">
                <li><a href="index.html">Home</a></li>
                <li><a href="projects.html">Projects</a></li>
                <li><a href="about.html">About</a></li>
                <li><a href="contact.html">Contact</a></li>
            </ul>
        </div>
    </nav>
    <header>
        <h1>Transfer Learning with PyTorch</h1>
        <p>Learn how to perform transfer learning using pre-trained models with PyTorch.</p>
    </header>

    <!-- Content Section -->
    <main>
        <!-- Step 1: Import Libraries -->
        <section class="step">
            <h2>Step 1: Import Libraries</h2>
            <p>
                In this step, we import the necessary PyTorch and other libraries.
            </p>
            <pre><code class="language-python">
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import torch.backends.cudnn as cudnn
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
from PIL import Image
from tempfile import TemporaryDirectory
from sklearn.model_selection import train_test_split
cudnn.benchmark = True
plt.ion()
            </code></pre>
        </section>

        <!-- Step 2: Data Augmentation and Normalization -->
        <section class="step">
            <h2>Step 2: Data Augmentation and Normalization</h2>
            <p>
                Here, we define data augmentation and normalization transformations for training and validation data.
            </p>
            <pre><code class="language-python">
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}
            </code></pre>
        </section>

        <!-- Step 3: Load and Split the Dataset -->
        <section class="step">
            <h2>Step 3: Load and Split the Dataset</h2>
            <p>
                We load the dataset and split it into training and validation sets.
            </p>
            <pre><code class="language-python">
data_dir = 'data'

# Load all the data first
full_dataset = datasets.ImageFolder(data_dir, transform=data_transforms['train'])

# Split the data into train and validation sets
train_size = 0.8
train_dataset, val_dataset = train_test_split(full_dataset, train_size=train_size, random_state=42)
            </code></pre>
        </section>

        <!-- Step 4: Create Data Loaders -->
        <section class="step">
            <h2>Step 4: Create Data Loaders</h2>
            <p>
                We create data loaders for both the training and validation sets.
            </p>
            <pre><code class="language-python">
dataloaders = {
    'train': torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4),
    'val': torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, num_workers=4)
}

dataset_sizes = {x: len(dataloader) for x, dataloader in dataloaders.items()}
class_names = full_dataset.classes

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
            </code></pre>
        </section>

        <!-- Step 5: Define Visualization Functions -->
        <section class="step">
            <h2>Step 5: Define Visualization Functions</h2>
            <p>
                Here, we define functions for visualizing the data and model predictions.
            </p>
            <pre><code class="language-python">
# Define a function to display images
def imshow(inp, title=None):
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.pause(0.001)

# Get a batch of training data
inputs, classes = next(iter(dataloaders['train']))

# Make a grid from batch
out = torchvision.utils.make_grid(inputs)

imshow(out, title=[class_names[x] for x in classes])
            </code></pre>
        </section>
        <!-- Step 6: Define the Train Model Function -->
        <section class="step">
            <h2>Step 6: Define the Train Model Function</h2>
            <p>
                In this step, we define a function for training the model using transfer learning.
            </p>
            <pre><code class="language-python">
# Define a function to train the model
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    since = time.time()

    # Create a temporary directory to save training checkpoints
    with TemporaryDirectory() as tempdir:
        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')

        torch.save(model.state_dict(), best_model_params_path)
        best_acc = 0.0

        for epoch in range(num_epochs):
            print(f'Epoch {epoch}/{num_epochs - 1}')
            print('-' * 10)

            # Each epoch has a training and validation phase
            for phase in ['train', 'val']:
                if phase == 'train':
                    model.train()  # Set model to training mode
                else:
                    model.eval()   # Set model to evaluate mode

                running_loss = 0.0
                running_corrects = 0

                # Iterate over data.
                for inputs, labels in dataloaders[phase]:
                    inputs = inputs.to(device)
                    labels = labels.to(device)

                    # zero the parameter gradients
                    optimizer.zero_grad()

                    # forward
                    # track history if only in train
                    with torch.set_grad_enabled(phase == 'train'):
                        outputs = model(inputs)
                        _, preds = torch.max(outputs, 1)
                        loss = criterion(outputs, labels)

                        # backward + optimize only if in training phase
                        if phase == 'train':
                            loss.backward()
                            optimizer.step()

                    # statistics
                    running_loss += loss.item() * inputs.size(0)
                    running_corrects += torch.sum(preds == labels.data)
                if phase == 'train':
                    scheduler.step()

                epoch_loss = running_loss / dataset_sizes[phase]
                epoch_acc = running_corrects.double() / dataset_sizes[phase]

                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

                # deep copy the model
                if phase == 'val' and epoch_acc > best_acc:
                    best_acc = epoch_acc
                    torch.save(model.state_dict(), best_model_params_path)

            print()

        time_elapsed = time.time() - since
        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
        print(f'Best val Acc: {best_acc:4f}')

        # load best model weights
        model.load_state_dict(torch.load(best_model_params_path))
    return model
            </code></pre>
        </section>
        <!-- Step 7: Visualize Model Predictions -->
        <section class="step">
            <h2>Step 7: Visualize Model Predictions</h2>
            <p>
                We define a function to visualize model predictions on a batch of images.
            </p>
            <pre><code class="language-python">
# Define a function to visualize model predictions
def visualize_model(model, num_images=6):
    was_training = model.training
    model.eval()
    images_so_far = 0
    fig = plt.figure()

    with torch.no_grad():
        for i, (inputs, labels) in enumerate(dataloaders['val']):
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            for j in range(inputs.size()[0]):
                images_so_far += 1
                ax = plt.subplot(num_images//2, 2, images_so_far)
                ax.axis('off')
                ax.set_title(f'predicted: {class_names[preds[j]]}')
                imshow(inputs.cpu().data[j])

                if images_so_far == num_images:
                    model.train(mode=was_training)
                    return
        model.train(mode=was_training)
            </code></pre>
        </section>

        <!-- Step 8: Load Pre-trained Model and Modify the Final Layer -->
        <section class="step">
            <h2>Step 8: Load Pre-trained Model and Modify the Final Layer</h2>
            <p>
                Here, we load a pre-trained ResNet-18 model and modify the final layer for transfer learning.
            </p>
            <pre><code class="language-python">
# Load a pre-trained ResNet-18 model
model_ft = models.resnet18(weights='IMAGENET1K_V1')
num_ftrs = model_ft.fc.in_features

# Modify the final layer for your specific classification task
model_ft.fc = nn.Linear(num_ftrs, 2)

model_ft = model_ft.to(device)

# Define the loss criterion
criterion = nn.CrossEntropyLoss()

# Observe that all parameters are being optimized
optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)

# Decay the learning rate by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)

# Train the model using transfer learning
model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)

# Visualize model predictions
visualize_model(model_ft)
            </code></pre>
        </section>

        <!-- Step 9: Fine-tune the Model -->
        <section class="step">
            <h2>Step 9: Fine-tune the Model</h2>
            <p>
                If needed, you can fine-tune the model by modifying specific layers and training for more epochs.
            </p>
            <pre><code class="language-python">
# Fine-tuning: Set requires_grad to False for all parameters except the final layer
model_conv = torchvision.models.resnet18(weights='IMAGENET1K_V1')
for param in model_conv.parameters():
    param.requires_grad = False

# Modify the final layer for your specific classification task
num_ftrs = model_conv.fc.in_features
model_conv.fc = nn.Linear(num_ftrs, 2)

model_conv = model_conv.to(device)

# Define the loss criterion
criterion = nn.CrossEntropyLoss()

# Observe that only parameters of the final layer are being optimized
optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)

# Decay the learning rate by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)

# Fine-tune the model
model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=25)

# Turn off interactive mode for plotting
plt.ioff()
plt.show()
            </code></pre>
        </section>

        <!-- Step 10: Make Predictions with the Fine-tuned Model -->
        <section class="step">
            <h2>Step 10: Make Predictions with the Fine-tuned Model</h2>
            <p>
                We define a function to make predictions using the fine-tuned model on a given image.
            </p>
            <pre><code class="language-python">
# Define a function to make predictions with the fine-tuned model
def visualize_model_predictions(model, img_path):
    was_training = model.training
    model.eval()

    img = Image.open(img_path)
    img = data_transforms['val'](img)
    img = img.unsqueeze(0)
    img = img.to(device)

    with torch.no_grad():
        outputs = model(img)
        _, preds = torch.max(outputs, 1)

        ax = plt.subplot(2, 2, 1)
        ax.axis('off')
        ax.set_title(f'Predicted: {class_names[preds[0]]}')
        imshow(img.cpu().data[0])

        model.train(mode=was_training)

# Make predictions with the fine-tuned model
img_path = input('Enter the image path: ')
visualize_model_predictions(model_conv, img_path)

# Turn off interactive mode for plotting
plt.ioff()
plt.show()
            </code></pre>
        </section>
    </main>

    <!-- Footer Section -->
    <footer>
        <div class="container">
            <p>&copy; 2023 Your Website. All Rights Reserved.</p>
        </div>
    </footer>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.27.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.27.0/components/prism-python.min.js"></script>
    <!-- Prism.js for code highlighting -->
 
</body>
</html>
