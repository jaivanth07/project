<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transfer Learning with TensorFlow</title>
    <link rel="stylesheet" type="text/css" href="style.css">
    <link rel="stylesheet" type="text/css" href="build.css">
    <link rel="stylesheet" type="text/css" href="rspt.css">

    <!-- Include Prism.js and your selected plugins -->
   
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.25.0/themes/prism-okaidia.css">
    
    <!-- Your custom CSS styles -->
    <link rel="stylesheet" type="text/css" href="styles.css">
</head>
<body>
    <!-- Header Section -->
    <nav class="navbar">
        <div class="container">
            <a href="index.html"> <img src="logo.png" alt="Logo" class="logo"></a>
            <ul class="nav-links">
                <li><a href="index.html">Home</a></li>
                <li><a href="projects.html">Projects</a></li>
                <li><a href="about.html">About</a></li>
                <li><a href="contact.html">Contact</a></li>
            </ul>
        </div>
    </nav>
    <header>
        <h1>Transfer Learning with TensorFlow</h1>
        <p>Learn how to perform transfer learning using pre-trained models with TensorFlow.</p>
    </header>

    <!-- Content Section -->
    <main>
        <!-- Step 1: Import Libraries -->
        <section class="step">
            <h2>Step 1: Import Libraries</h2>
            <p>
                In this step, we import the necessary libraries, including TensorFlow, Matplotlib, and NumPy.
            </p>
            <pre><code class="language-python">
import matplotlib.pyplot as plt
import numpy as np
import os
import tensorflow as tf
            </code></pre>
        </section>

        <!-- Step 2: Define Dataset and Data Augmentation -->
        <section class="step">
            <h2>Step 2: Define Dataset and Data Augmentation</h2>
            <p>
                Here, we define the path to our dataset, create data augmentation techniques, and set the batch size.
            </p>
            <pre><code class="language-python">
# Define the path to your dataset folder
data_dir = 'data'

# Use data augmentation and preprocessing
data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip('horizontal'),
    tf.keras.layers.RandomRotation(0.2),
])

# Define the batch size
batch_size = 32
            </code></pre>
        </section>

        <!-- Step 3: Create Data Generators -->
        <section class="step">
            <h2>Step 3: Create Data Generators</h2>
            <p>
                In this step, we create data generators for the training and validation sets. We apply rescaling and data augmentation to the images.
            </p>
            <pre><code class="language-python">
# Create a data generator for your dataset
datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1. / 255,
    validation_split=0.2,
    preprocessing_function=data_augmentation
)
            </code></pre>
        </section>

        <!-- Step 4: Load and Prepare Dataset -->
        <section class="step">
            <h2>Step 4: Load and Prepare Dataset</h2>
            <p>
                We load and prepare the dataset using flow_from_directory for both the training and validation sets.
            </p>
            <pre><code class="language-python">
# Load the dataset using flow_from_directory
IMG_SIZE = (160, 160)
train_dataset = datagen.flow_from_directory(
    data_dir,
    target_size=IMG_SIZE,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

validation_dataset = datagen.flow_from_directory(
    data_dir,
    target_size=IMG_SIZE,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)
            </code></pre>
        </section>

        <!-- Step 5: Define Model Architecture -->
        <section class="step">
            <h2>Step 5: Define Model Architecture</h2>
            <p>
                In this step, we define our model architecture. We use the MobileNetV2 pre-trained model as the base and add a custom classification head.
            </p>
            <pre><code class="language-python">
# Define your model architecture
base_model = tf.keras.applications.MobileNetV2(
    input_shape=IMG_SIZE + (3,),
    include_top=False,
    weights='imagenet'
)

# Add your classification head
num_classes = 4  # Replace with your number of classes
global_average_layer = tf.keras.layers.GlobalAveragePooling2D()
x = global_average_layer(base_model.output)
x = tf.keras.layers.Dropout(0.2)(x)
outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)

# Create the final model
model = tf.keras.Model(inputs=base_model.input, outputs=outputs)
            </code></pre>
        </section>

        <!-- Step 6: Compile the Model -->
        <section class="step">
            <h2>Step 6: Compile the Model</h2>
            <p>
                Here, we compile the model with an optimizer, loss function, and evaluation metric.
            </p>
            <pre><code class="language-python">
# Compile your model
base_learning_rate = 0.0001
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),
              loss='categorical_crossentropy',
              metrics=['accuracy'])
            </code></pre>
        </section>

        <!-- Step 7: Train the Model -->
        <section class="step">
            <h2>Step 7: Train the Model</h2>
            <p>
                We train the model with an initial number of epochs.
            </p>
            <pre><code class="language-python">
# Training
initial_epochs = 10
history = model.fit(train_dataset,
                    epochs=initial_epochs,
                    validation_data=validation_dataset)
            </code></pre>
        </section>

        <!-- Step 8: Evaluate the Model -->
        <section class="step">
            <h2>Step 8: Evaluate the Model</h2>
            <p>
                After training, we evaluate the model's performance on the validation dataset.
            </p>
            <pre><code class="language-python">
# Evaluate the model on the test dataset
test_loss, test_accuracy = model.evaluate(validation_dataset)
print("Test Loss: {:.2f}".format(test_loss))
print("Test Accuracy: {:.2f}%".format(test_accuracy * 100))
            </code></pre>
        </section>

        <!-- Step 9: Fine-tuning (if needed) -->
        <section class="step">
            <h2>Step 9: Fine-tuning (if needed)</h2>
            <p>
                If necessary, you can fine-tune the model by unfreezing certain layers and training for additional epochs.
            </p>
            <pre><code class="language-python">
# Fine-tuning (if needed)
base_model.trainable = True
fine_tune_at = 100
for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False

fine_tune_epochs = 10
total_epochs = initial_epochs + fine_tune_epochs

model.compile(loss='categorical_crossentropy',
              optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate / 10),
              metrics=['accuracy'])

history_fine = model.fit(train_dataset,
                         epochs=total_epochs,
                         initial_epoch=initial_epochs,
                         validation_data=validation_dataset)

# Test your model on the test dataset again
test_loss, test_accuracy = model.evaluate(validation_dataset)
print("Test Loss after fine-tuning: {:.2f}".format(test_loss))
print("Test Accuracy after fine-tuning: {:.2f}%".format(test_accuracy * 100))
            </code></pre>
        </section>

        <!-- Step 10: Make Predictions -->
        <section class="step">
            <h2>Step 10: Make Predictions</h2>
            <p>
                Finally, we make predictions on a batch of images and evaluate the model's performance.
            </p>
            <pre><code class="language-python">
# Make predictions on a batch of images
# Retrieve a batch of images from the validation set
image_batch, label_batch = validation_dataset.as_numpy_iterator().next()

# Get predictions from the model
predictions = model.predict(image_batch)

# Calculate predicted labels
predicted_labels = np.argmax(predictions, axis=1)

# Convert softmax predictions to class labels
predicted_labels = np.argmax(predictions, axis=1)
true_labels = np.argmax(label_batch, axis=1)

print("Predicted Labels:", predicted_labels)
print("True Labels:", true_labels)
            </code></pre>
        </section>
    </main>
    <script src="script.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.27.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.27.0/components/prism-python.min.js"></script>
</body>
</html>
